{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-class Work\n",
    "\n",
    "Speaker identification\n",
    "â€‹\n",
    "\n",
    "There are three people in a room. Each says about 10 phonemes, before being randomly interrupted by someone else. When they speak they all sound the same, however each person tends to use different phonemes in their speech. Specifically we can model the following transition probabilities that someone will interrupt the current speaker: P(speaker i at time t+1 | speaker j at time t). We can also model the probability over phonemes given a particular speaker: P(phoneme | speaker i). The phonemes are identical to the ones introduced in problem 1 (but the transition matrices are obviously different, since they take a different form altogether).\n",
    "\n",
    "+ Write down the update equations that you will need to train a hidden Markov model. \n",
    "+ Using the information given above, write down a sensible initialization for the transition matrix.\n",
    "+ Write your own python code to train a hidden Markov model on the data. You may look at code online, but will need to reference any code that helps you with your implementation.\n",
    "+ From matplotlb use a stackplot (https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.stackplot.html) to show the probability of a particular person speaking.\n",
    "+ Audio dataset: https://course-resources.minerva.kgi.edu/uploaded_files/mke/VW8Rjr/speaker.wav.zip\n",
    "+ Symbol dataset: https://course-resources.minerva.kgi.edu/uploaded_files/mke/n705lY/speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'p', 'o', 'g', 'e', 'k', 't']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = open(\"speaker.txt\").read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eoggeggAeg'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i wrote this function but the helper functions, i modified from code here: \n",
    "#https://sambaiga.github.io/2017/05/03/hmm-intro.html\n",
    "def baum_welch(data, prior = 1/7):\n",
    "    unique_characters = list(set(data))\n",
    "    transition = np.random.rand(7,7)\n",
    "    emission = np.random.rand(7,7)\n",
    "    for i in range(len(data)):\n",
    "        alpha = forward(transition, emission, data, prior)\n",
    "        beta = backward(transition, emission, data)\n",
    "        g = gamma(transition, emission, data, prior)\n",
    "        e = epsilon(transition, emission, data, prior)\n",
    "        g2 = gamma(transition, emission, data, prior)\n",
    "        transition = tr(e, g)\n",
    "        emission = em(g2, g)\n",
    "    return transition, emission\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'p': 1, 'o': 2, 'g': 3, 'e': 4, 'k': 5, 't': 6}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([(i[1], i[0]) for i in list(enumerate(unique_characters))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified code from \n",
    "\n",
    "def forward(A, B, obs_seq, prior):\n",
    "    unique_characters = list(set(obs_seq))\n",
    "    dic = dict([(i[1], i[0]) for i in list(enumerate(unique_characters))])\n",
    "    T = len(obs_seq)\n",
    "    N = A.shape[0]\n",
    "    alpha = np.zeros((T, N))\n",
    "    alpha[0] = prior*B[:, dic[obs_seq[0]]]\n",
    "    for t in range(1, T):\n",
    "        alpha[t] = alpha[t-1].dot(A) * B[:, dic[obs_seq[t]]]\n",
    "    return alpha\n",
    "    \n",
    "def backward(A, B, obs_seq):\n",
    "    unique_characters = list(set(obs_seq))\n",
    "    dic = dict([(i[1], i[0]) for i in list(enumerate(unique_characters))])\n",
    "    N = A.shape[0]\n",
    "    T = len(obs_seq)\n",
    "\n",
    "    beta = np.zeros((N,T))\n",
    "    beta[:,-1:] = 1\n",
    "\n",
    "    for t in reversed(range(T-1)):\n",
    "        for n in range(N):\n",
    "            beta[n,t] = np.sum(beta[:,t+1] * A[n,:] * B[:, dic[obs_seq[t+1]]])\n",
    "            \n",
    "\n",
    "    return beta\n",
    "\n",
    "def gamma(A, B, obs_seq, prior):\n",
    "    alpha = forward(A, B, obs_seq, prior)\n",
    "    beta  = backward(A, B, obs_seq)\n",
    "    obs_prob = alpha[-1].sum()\n",
    "    #print(alpha.shape)\n",
    "    return (np.dot(alpha,beta) / obs_prob)\n",
    "\n",
    "\n",
    "def epsilon(A, B, obs_seq, prior):\n",
    "    alpha = forward(A, B, obs_seq, prior)\n",
    "    beta  = backward(A, B, obs_seq)\n",
    "    obs_prob = alpha[-1].sum()\n",
    "    return (np.dot(np.dot(np.dot(alpha,A), B), beta)) / obs_prob\n",
    "\n",
    "def tr(e, g):\n",
    "    return e/g\n",
    "    \n",
    "def em(g1, g2):\n",
    "    return g1/g2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_characters = list(set(data))\n",
    "# transition = np.random.rand(7,7)\n",
    "# emission = np.random.rand(7,7)\n",
    "# for i in range(len(data)):\n",
    "#     alpha = forward(transition, emission, data, 1/7)\n",
    "#     beta = backward(transition, emission, data)\n",
    "#     g = gamma(transition, emission, data, 1/7)#alpha, beta, emission, transition)\n",
    "# #     e = epsilon(alpha, beta, emission, transition)\n",
    "# #     g2 = gamma(alpha, beta, emission, transition)\n",
    "# #     transition = tr(e, g)\n",
    "# #     emission = em(g2/g)\n",
    "# # return transition, emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-4c7f388d5a62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mbaum_welch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-141-4c7f388d5a62>\u001b[0m in \u001b[0;36mbaum_welch\u001b[0;34m(training, pi, A, O, iterations)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mobservations\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# compute forward-backward matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mza\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mza\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mzb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"it's badness 10000 if the marginals don't agree\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-141-4c7f388d5a62>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(params, observations)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# base case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# recursive case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "def forward(params, observations):\n",
    "    pi, A, O = params\n",
    "    N = len(observations)\n",
    "    S = pi.shape[0]\n",
    "    \n",
    "    alpha = np.zeros((N, S))\n",
    "    \n",
    "    # base case\n",
    "    alpha[0, :] = pi * O[:,observations[0]]\n",
    "    \n",
    "    # recursive case\n",
    "    for i in range(1, N):\n",
    "        for s2 in range(S):\n",
    "            for s1 in range(S):\n",
    "                alpha[i, s2] += alpha[i-1, s1] * A[s1, s2] * O[s2, observations[i]]\n",
    "    \n",
    "    return (alpha, np.sum(alpha[N-1,:]))\n",
    "\n",
    "def backward(params, observations):\n",
    "    pi, A, O = params\n",
    "    N = len(observations)\n",
    "    S = pi.shape[0]\n",
    "    \n",
    "    beta = np.zeros((N, S))\n",
    "    \n",
    "    # base case\n",
    "    beta[N-1, :] = 1\n",
    "    \n",
    "    # recursive case\n",
    "    for i in range(N-2, -1, -1):\n",
    "        for s1 in range(S):\n",
    "            for s2 in range(S):\n",
    "                beta[i, s1] += beta[i+1, s2] * A[s1, s2] * O[s2, observations[i+1]]\n",
    "    \n",
    "    return (beta, np.sum(pi * O[:, observations[0]] * beta[0,:]))\n",
    "\n",
    "def baum_welch(training, pi, A, O, iterations):\n",
    "    pi, A, O = np.copy(pi), np.copy(A), np.copy(O) # take copies, as we modify them\n",
    "    S = pi.shape[0]\n",
    "    \n",
    "    # do several steps of EM hill climbing\n",
    "    for it in range(iterations):\n",
    "        pi1 = np.zeros_like(pi)\n",
    "        A1 = np.zeros_like(A)\n",
    "        O1 = np.zeros_like(O)\n",
    "        \n",
    "        for observations in training:\n",
    "            # compute forward-backward matrices\n",
    "            alpha, za = forward((pi, A, O), observations)\n",
    "            beta, zb = backward((pi, A, O), observations)\n",
    "            assert abs(za - zb) < 1e-6, \"it's badness 10000 if the marginals don't agree\"\n",
    "            \n",
    "            # M-step here, calculating the frequency of starting state, transitions and (state, obs) pairs\n",
    "            pi1 += alpha[0,:] * beta[0,:] / za\n",
    "            for i in range(0, len(observations)):\n",
    "                O1[:, observations[i]] += alpha[i,:] * beta[i,:] / za\n",
    "            for i in range(1, len(observations)):\n",
    "                for s1 in range(S):\n",
    "                    for s2 in range(S):\n",
    "                        A1[s1, s2] += alpha[i-1,s1] * A[s1, s2] * O[s2, observations[i]] * beta[i,s2] / za\n",
    "                                                                    \n",
    "        # normalise pi1, A1, O1\n",
    "        pi = pi1 / np.sum(pi1)\n",
    "        for s in range(S):\n",
    "            A[s, :] = A1[s, :] / np.sum(A1[s, :])\n",
    "            O[s, :] = O1[s, :] / np.sum(O1[s, :])\n",
    "    \n",
    "    return pi, A, O\n",
    "\n",
    "baum_welch(data, [1/7 for i in range(7)], transition, emission, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition, emission = baum_welch(data[:10], 1/7)\n",
    "emission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n",
      "(1000, 1000) (1000, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "prior = 1/7\n",
    "unique_characters = list(set(data))\n",
    "transition = np.random.rand(7,7)\n",
    "emission = np.random.rand(7,7)\n",
    "for i in range(len(data)):\n",
    "    alpha = forward(transition, emission, data, prior)\n",
    "    beta = backward(transition, emission, data)\n",
    "    g = gamma(transition, emission, data, prior)\n",
    "    e = epsilon(transition, emission, data, prior)\n",
    "    g2 = gamma(transition, emission, data, prior)\n",
    "    print(e.shape)\n",
    "    transition = tr(e, g)\n",
    "    emission = em(g2, g)\n",
    "    print(transition.shape, emission.shape)\n",
    "    #print(transition.shape)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Guide\n",
    "\n",
    "After the reading and the pre-class work you should be able to answer the following questions:\n",
    "What is filtering (with reference to a hidden Markov model)? Give a compelling real-world example.\n",
    "+ to find p(h_t|v_1:t)\n",
    "What is smoothing (with reference to a hidden Markov model)? Give a compelling real-world example.\n",
    "+ to find p(h_T|v_1:T)\n",
    "What is prediction (with reference to a hidden Markov model)? Give a compelling real-world example.\n",
    "+ p(v_t+1|v_t)\n",
    "With reference to a Hidden Markov model, what is a transition matrix and what is an emission matrix?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
