{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>MNIST Digits - Kernel Functions</h2>\n",
    "\n",
    "1. Load the entire MNIST digit dataset: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/ \"http://yann.lecun.com/exdb/mnist/\"%29.\n",
    "\n",
    "2. Choose two digit classes (e.g 7s and 3s) from the training data, and plot some of the examples.\n",
    "\n",
    "3. Train a support vector classifier using each of the following kernels:\n",
    "\n",
    "    - Linear\n",
    "    - Poly\n",
    "    - RBF\n",
    "    \n",
    "\n",
    "4. Report your training times on the dataset for the different kernels.\n",
    "\n",
    "5. Report your error rates on the testing dataset for the different kernels.\n",
    "\n",
    "    (If you encounter any issues with training time or memory issues, then you may use a reduced dataset, but carefully detail how you reduced the dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import MNIST dataset\n",
    "from six.moves import urllib\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from scipy.io import loadmat\n",
    "mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
    "mnist_path = \"./mnist-original.mat\"\n",
    "response = urllib.request.urlopen(mnist_alternative_url)\n",
    "with open(mnist_path, \"wb\") as f:\n",
    "    content = response.read()\n",
    "    f.write(content)\n",
    "mnist_raw = loadmat(mnist_path)\n",
    "mnist = {\n",
    "    \"data\": mnist_raw[\"data\"].T,\n",
    "    \"target\": mnist_raw[\"label\"][0],\n",
    "    \"COL_NAMES\": [\"label\", \"data\"],\n",
    "    \"DESCR\": \"mldata.org dataset: mnist-original\",\n",
    "}\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Size of MNIST digit dataset: {mnist['data'].shape}\")\n",
    "\n",
    "#take a peak at the MNIST dataset structure\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data, mnist_target = mnist['data'], mnist['target']\n",
    "\n",
    "#filter out only 2 and 7 to be used for training\n",
    "number_filter = np.where((mnist_target == 2 ) | (mnist_target == 7))\n",
    "mnist_data, mnist_target = mnist_data[number_filter], mnist_target[number_filter]\n",
    "\n",
    "def plot_digits(title, data):\n",
    "    print(title)\n",
    "    for index,image in enumerate(data[:10]):\n",
    "        image = image.reshape(28,28)\n",
    "        plt.subplot(2, 5, index + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "plot_digits('Seven',mnist_data[np.where(mnist_target == 7)])\n",
    "plot_digits('Two',mnist_data[np.where(mnist_target == 2)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the dataset into training and testing data\n",
    "X_train,X_test,y_train,y_test = train_test_split(mnist_data,mnist_target,test_size=0.3)\n",
    "\n",
    "#check the dimensions of the datasets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_svm(svc, X_train, X_test, y_train, y_test, demo = False):\n",
    "    '''\n",
    "    Inputs: \n",
    "    - svc: Initialized svc instance.\n",
    "    - demo: Boolean. If set to True, will print out outputs when running.\n",
    "    \n",
    "    Outputs: \n",
    "    - train_time: CPU processing training time (ms)\n",
    "    - test_time: CPU processing testing time (ms)\n",
    "    - train_score: Model score on the training data\n",
    "    - test_score: Model score on the testing data\n",
    "    '''\n",
    "    \n",
    "    #train model\n",
    "    train_start = time.process_time()\n",
    "    \n",
    "    model = svc.fit(X_train, y_train) \n",
    "    \n",
    "    train_stop = time.process_time()\n",
    "    \n",
    "    #test model\n",
    "    test_start = time.process_time()\n",
    "    \n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    test_stop = time.process_time()\n",
    "    \n",
    "    #multiply recorded times by 1000 to get milliseconds\n",
    "    train_time = (train_stop - train_start)*1000\n",
    "    test_time = (test_stop - test_start)*1000\n",
    "    \n",
    "    if demo:\n",
    "        print(f'Train time')\n",
    "        print(f'CPU process time: {round(train_time,2)} ms')\n",
    "\n",
    "        print(f'\\nTest time')\n",
    "        print(f'CPU process time: {round(test_time,2)} ms')\n",
    "\n",
    "        print(f'Model score: {round(test_score,4)}')\n",
    "        \n",
    "    return train_time, test_time, train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "kernels = ['linear','poly','rbf']\n",
    "\n",
    "#create empty numpy array to store results\n",
    "results = np.zeros([len(kernels),5])\n",
    "\n",
    "#train and test SVCs with different kernels on MNIST data (2s and 7s)\n",
    "for i in range(len(kernels)):\n",
    "    \n",
    "    #initiate the SVC classifier\n",
    "    svc = SVC(kernel=kernels[i])\n",
    "    \n",
    "    #get the time taken for training & testing, and the model score\n",
    "    train_time, test_time, train_score, test_score = train_test_svm(svc, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    #store results\n",
    "    results[i,:] = i, round(train_time,2), round(test_time,2), round(train_score,4), round(test_score,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, \n",
    "                  columns=['Kernels',\n",
    "                           'Training CPU Processing Time (ms)',\n",
    "                           'Testing CPU Processing Time (ms)',\n",
    "                           'Training score',\n",
    "                           'Testing score'])\n",
    "df['Kernels'] = kernels\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(df['Kernels'], df['Training CPU Processing Time (ms)'], label='Train time', alpha=0.7, width=0.5)\n",
    "plt.bar(df['Kernels'], df['Testing CPU Processing Time (ms)'], label='Test time', alpha=0.8, width=0.5)\n",
    "plt.xlabel('Kernel', size=15)\n",
    "plt.ylabel('CPU Processing Time (ms)', size=15)\n",
    "plt.title('Bar plot of CPU processing time (ms) across different kernels', size=15)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(df['Kernels'], df['Testing score'], label='Test Scores', alpha=0.8, width=0.5)\n",
    "plt.xlabel('Kernel', size=15)\n",
    "plt.ylabel('Test Score', size=15)\n",
    "plt.title('Plot of Test Score across different kernels', size=15)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Summary</h2>\n",
    "\n",
    "The results show that the the linear kernel had the fastest testing time (3636 ms) on 4285 data points, while the polynomial kernel had the fastest training time (4499 ms) on 9998 data points. Since the difference between the linear and polynomial training and testing times are small (1-2 seconds), we can assume that the linear and polynomial kernels had roughly the same time for both training and testing.\n",
    "\n",
    "The radial basis function (rbf) kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#use PCA for filtering noise\n",
    "\n",
    "#preserve 50% of the variance in the data\n",
    "pca = PCA(0.50).fit(mnist_data)\n",
    "print(f\"Number of principle components: {pca.n_components_}\")\n",
    "\n",
    "components = pca.transform(mnist_data)\n",
    "pca_data = pca.inverse_transform(components)\n",
    "\n",
    "plot_digits('Filtered Seven', pca_data[np.where(mnist_target == 7)])\n",
    "plot_digits('Filtered Two', pca_data[np.where(mnist_target == 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the filtered dataset into training and testing data\n",
    "pca_X_train,pca_X_test,pca_y_train,pca_y_test = train_test_split(pca_data,mnist_target,test_size=0.3)\n",
    "\n",
    "#create empty numpy array to store results\n",
    "pca_results = np.zeros([len(kernels),5])\n",
    "\n",
    "#train and test SVCs with different kernels on MNIST data (2s and 7s)\n",
    "for i in range(len(kernels)):\n",
    "    \n",
    "    #initiate the SVC classifier\n",
    "    svc = SVC(kernel=kernels[i])\n",
    "    \n",
    "    #get the time taken for training & testing, and the model score\n",
    "    train_time, test_time, train_score, test_score = train_test_svm(svc, pca_X_train, pca_X_test, pca_y_train, pca_y_test)\n",
    "    \n",
    "    #store results\n",
    "    pca_results[i,:] = i, round(train_time,2), round(test_time,2), round(train_score,4), round(test_score,4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(pca_results, \n",
    "                  columns=['Kernels',\n",
    "                           'Training CPU Processing Time (ms)',\n",
    "                           'Testing CPU Processing Time (ms)',\n",
    "                           'Training score',\n",
    "                           'Testing score'])\n",
    "pca_df['Kernels'] = kernels\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(pca_df['Kernels'], pca_df['Training CPU Processing Time (ms)'], label='Train time', alpha=0.7, width=0.5)\n",
    "plt.bar(pca_df['Kernels'], pca_df['Testing CPU Processing Time (ms)'], label='Test time', alpha=0.8, width=0.5)\n",
    "plt.xlabel('Kernel', size=15)\n",
    "plt.ylabel('CPU Processing Time (ms)', size=15)\n",
    "plt.title('Bar plot of CPU processing time (ms) across different kernels', size=15)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(pca_df['Kernels'], pca_df['Testing score'], label='Test Scores', alpha=0.8, width=0.5)\n",
    "plt.xlabel('Kernel', size=15)\n",
    "plt.ylabel('Test Score', size=15)\n",
    "plt.title('Plot of Test Score across different kernels', size=15)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
